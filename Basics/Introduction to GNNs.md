*Date：2026-02-16*
- 学到的知识
	- 描述一个图有V（顶点）和E（边），还有邻接矩阵，这些都是字面意思
	- GNN主要是GCN，图卷积神经网络，分空域和频域，空域就是上面直接用图的V和E去描述，涉及节点和边之间的信息交互，有点像LDPC的“置信度传播算法”，频域要对邻接矩阵做特征值分析
- **如何表示PCB的“铺铜”？** 即，从一个驱动端同时连接到很多个负载端，且相互之间都是等电位的
	1. Star Expansion，星型展开：源点Source像太阳，负载点Sink像行星。很省内存。但是，在这种结构下，Sink A 和 Sink B 之间没有直接连线。如果要传递信息，必须经过 Source，路径为A -> Source -> B。但是在真实的电路板或芯片上，这些Sink共享同一个电压电位。在物理布局时，我们希望这 100 个点不仅仅是离 Source 近，它们互相之间也要近。如果只用Star Expansion，GNN 可能会觉得 A 和 B 关系不大，导致布局的时候把 A 和 B 拉得很远，结果布线的时候线就不够用了。
		- GraphSAGE (SAmple and aggreGatE)
			- 有些点（比如时钟源）连了10万个点，计算它时，要聚合10万个邻居，显存直接爆炸
			- 解决方案是：随机采样。不管有多少相邻的点，每次只随机抽少量相邻的点来代表周围的点
			- 用来处理超大扇出节点
	2. Clique Expansion，全连接：两两相连，费内存。
- **对于有上亿个节点的图，邻接矩阵是存不下的**
	- 邻接表法：只存两个列表：
		- Row (起点): `[0, 0, 1, 2, ...]
		- Col (终点): `[1, 5, 2, 0, ...]`
		- 意思就是：节点 0 连向 1，0 连向 5，1 连向 2...
		- 这就是edge_index，边索引。 不管图有一亿个点还是十亿个点，只要边只有几百万条，我只存这几百万条记录，省内存
- **空域VS频域**
	- 空域模拟的是“信息传递”，频域模拟的是“固有频率”
	- 频域 GNN 假设图的结构是固定的。但我们在 EDA 流程中，经常要根据预测结果去挪动节点、甚至改变布线，图是动态变化的
	- GAT (Graph Attention Network)
		- GCN 认为所有邻居的重要性是一样的（取平均值）
		- 解决方案是：注意力机制。对于 EDA 来说，连在“关键路径（Critical Path）”上的邻居，肯定比普通邻居更重要，GAT 会给关键邻居更高的权重
		- 在时序分析里非常有用，因为时序只取决于那条最慢的路。